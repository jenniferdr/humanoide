\section{Inteligencia Artificial} \label{sect:Inteligencia_Artificial}
La inteligencia artificial es un término relacionado con la computación y la robótica que ha tenido varias definiciones, ocho de ellas, las cuales nacieron a finales del siglo XX, se encuentran organizadas en \cite{peterNorvig} bajo cuatro categorías: pensar y actuar de forma humana, pensar y actuar de forma racional. Con ello se puede entender que la inteligencia artificial tiene que ver con lograr que un robot resuelve problemas de manera inteligente, es decir, de manera que parezca que el razonamiento y comportamiento humano las ha resuelto.  

\subsection{ Aprendizaje de Máquinas}
El aprendizaje de máquinas es un área de la inteligencia artificial que está relacionada con la pregunta de cómo construir programas de computadora que automáticamente mejoren con la experiencia. Se dice que un programa aprende de la experiencia E con respecto a una tarea T y desempeño P. Si el desempeño en la tarea T, medido por P, mejora con con la experiencia E \cite{Mitchell}
\subsection{Aprendizaje por reforzamiento}
El aprendizaje por reforzamiento es un tipo de aprendizaje de máquinas que se basa en un sistema de recompensas y penalizaciones. Las recompensas se pueden dar en cada estado o una sola vez al llegar al estado final.

El objetivo del agente es aprender de las recompensas para escoger la secuencia de acciones que produzca la mayor recompensa acumulada. \cite{Mitchell}

<<<<<<< HEAD
El agente existe en un entorno descrito por algunos estados S. Puede ejecutar un conjunto de acciones A. Cada vez que ejecuta una acción ‘at’ en algún estado ‘at’ el agente recibe una recompensa ‘rt’. El objetivo es aprender una política pi : S \- A que maximice la suma esperada de esas recompensas con descuento exponencial de las recompensas futuras. \cite{Mitchell} El resultado de tomar las acciones puede ser determinista o no, en el caso de este proyecto no es deterninista, es decir, existen porcentajes de probabilidad de pasar a un estado u otro al tomar una acción en un estado en particular.  
=======
El agente existe en un entorno descrito por algunos estados S. Puede ejecutar un conjunto de acciones A. Cada vez que ejecuta una acción a_{t} en algún estado s_{t} el agente recibe una recompensa r_{t}. El objetivo es aprender una política pi : S /rightarrow A que maximice la suma esperada de esas recompensas con descuento exponencial de las recompensas futuras. (Mitchell) El resultado de tomar las acciones puede ser determinista o no, en el caso de este proyecto no es determinista, es decir, existen porcentajes de probabilidad de pasar a un estado u otro al tomar una acción en un estado en particular.  
>>>>>>> 667cf8b3e5b67281d85d6dc28071a6bdf5c07261

\subsection{ Q- learning}

Es un método de aprendizaje por reforzamiento

Compara las utilidades esperadas de acciones posibles sin necesidad de saber el resultado por tanto no se necesita un modelo del entorno \cite{peterNorvig}

